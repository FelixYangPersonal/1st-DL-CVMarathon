{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0WL12BsaEvPa"
   },
   "source": [
    "## 『本次練習內容』\n",
    "#### 使用Xception backbone做 Trnasfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svjBJ5bTEvPd"
   },
   "source": [
    "## 『本次練習目的』\n",
    "  #### 了解如何使用Transfer Learning\n",
    "  #### 了解Transfer Learning的優點，可以觀察模型收斂速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rDlVNdMuEvPe"
   },
   "source": [
    "##### 可以自行嘗試多種架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kGpm7zHkEvPf",
    "outputId": "4b03ba8b-5f0b-4d75-f6fb-5dc778438630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Convolution2D, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    " \n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "okvjXL7MEvPi",
    "outputId": "3bb7509c-f0fb-400a-a25a-adce498b4775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 7s 0us/step\n",
      "Model: \"xception\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 15, 15, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 15, 15, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 15, 15, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 13, 13, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 13, 13, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 13, 13, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 13, 13, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 13, 13, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 13, 13, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 13, 13, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 7, 7, 128)    8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 7, 7, 128)    0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 7, 7, 128)    512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 7, 7, 128)    0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 7, 7, 128)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 7, 7, 256)    33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 7, 7, 256)    0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 7, 7, 256)    67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 7, 7, 256)    1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 4, 4, 256)    32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 4, 4, 256)    0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4, 4, 256)    1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4, 4, 256)    0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 4, 4, 256)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 4, 4, 728)    188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 4, 4, 728)    0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 4, 4, 728)    536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 4, 4, 728)    2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 2, 2, 728)    186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 2, 2, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2, 2, 728)    2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2, 2, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 2, 2, 728)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 2, 2, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 2, 2, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2, 2, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 2, 2, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 2, 2, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 2, 2, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 2, 2, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 2, 2, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 2, 2, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 2, 2, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 2, 2, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 2, 2, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 2, 2, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 2, 2, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 2, 2, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 2, 2, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 2, 2, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 2, 2, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 2, 2, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 2, 2, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 2, 2, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 2, 2, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 2, 2, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 2, 2, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 2, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 2, 2, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 2, 2, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 2, 2, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 2, 2, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 2, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 2, 2, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 2, 2, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 2, 2, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 2, 2, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 2, 2, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 2, 2, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 1, 1, 1024)   745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 1, 1, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 1, 1024)   4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1, 1, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 1, 1, 1536)   1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 1, 1, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 1, 1, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 1, 1, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 1, 1, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 1, 1, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "#include top 決定要不要加入 fully Connected Layer\n",
    "\n",
    "'''Xception 架構'''\n",
    "model = tensorflow.keras.applications.xception.Xception(include_top=False, weights='imagenet',\n",
    "                                                        input_tensor=input_tensor,\n",
    "                                                        pooling=None, classes=1000)\n",
    "  \n",
    "'''Resnet 50 架構'''\n",
    "# model = tensorflow.keras.applications.ResNet50(include_top=False, weights='imagenet',\n",
    "#                                                input_tensor=input_tensor,\n",
    "#                                                pooling=None, classes=10)\n",
    "  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CqP82OYgEvPk"
   },
   "source": [
    "## 添加層數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t3Ij8C3ZEvPl",
    "outputId": "ff732498-57f4-4c03-86dc-13183d7036b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model深度： 141\n"
     ]
    }
   ],
   "source": [
    "x = model.output\n",
    "  \n",
    "'''可以參考Cifar10實作章節'''\n",
    "# BatchNormalization皆不使用時，Model深度為139\n",
    "x = Convolution2D(32, (1,1), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution2D(64, (1,1))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(1,1))(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=100, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(units=10, activation='softmax')(x)\n",
    "model = Model(inputs=model.input, outputs=predictions)\n",
    "  \n",
    "print('Model深度：', len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iC5JEBqyEvPp"
   },
   "source": [
    "## 鎖定特定幾層不要更新權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r6H7AaEJEvPp"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:100]:\n",
    "  layer.trainable = False\n",
    "    \n",
    "for layer in model.layers[100:]:\n",
    "  layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JY0RTowCEvPs"
   },
   "source": [
    "## 準備 Cifar 10 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "4_y6huI4EvPs",
    "outputId": "1b2263d8-d67e-4f8f-8316-c70265e3f81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 13s 0us/step\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train, X_test):\n",
    "    mean = np.mean(X_train, axis=(0, 1, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "    X_train = (X_train - mean) / (std + 1e-7)\n",
    "    X_test = (X_test - mean) / (std + 1e-7)\n",
    "    \n",
    "    return X_train, X_test    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test = normalize(x_train, x_test) \n",
    "\n",
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot = OneHotEncoder(categories='auto')\n",
    "y_train = one_hot.fit_transform(y_train).toarray()\n",
    "y_test = one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40MOhMi1EvPv"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-jMpqTIFEvPw",
    "outputId": "b75bfb6a-f30b-473e-ee8b-034b212ebb75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 39s 771us/sample - loss: 1.6670 - accuracy: 0.3928\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 28s 560us/sample - loss: 1.1730 - accuracy: 0.6016\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 28s 567us/sample - loss: 1.0184 - accuracy: 0.6525\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 29s 571us/sample - loss: 0.9106 - accuracy: 0.6915\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 29s 577us/sample - loss: 0.8318 - accuracy: 0.7163\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.7514 - accuracy: 0.7438\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 29s 582us/sample - loss: 0.6693 - accuracy: 0.7718\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 29s 575us/sample - loss: 0.6060 - accuracy: 0.7910\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.5396 - accuracy: 0.8152\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.4903 - accuracy: 0.8329\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 29s 580us/sample - loss: 0.4459 - accuracy: 0.8482\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.3993 - accuracy: 0.8632\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 29s 581us/sample - loss: 0.3634 - accuracy: 0.8765\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.3282 - accuracy: 0.8875\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.3033 - accuracy: 0.8974\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.2846 - accuracy: 0.9040\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 29s 581us/sample - loss: 0.2629 - accuracy: 0.9103\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.2520 - accuracy: 0.9153\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.2396 - accuracy: 0.9181\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 29s 577us/sample - loss: 0.2260 - accuracy: 0.9216\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.2119 - accuracy: 0.9289\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.2081 - accuracy: 0.9299\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 29s 577us/sample - loss: 0.1934 - accuracy: 0.9352\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.1826 - accuracy: 0.9379\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 29s 575us/sample - loss: 0.1847 - accuracy: 0.9376\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.1739 - accuracy: 0.9413\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 29s 577us/sample - loss: 0.1681 - accuracy: 0.9432\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 29s 581us/sample - loss: 0.1671 - accuracy: 0.9423\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 29s 575us/sample - loss: 0.1542 - accuracy: 0.9479\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.1515 - accuracy: 0.9479\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 29s 575us/sample - loss: 0.1494 - accuracy: 0.9498\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.1477 - accuracy: 0.9505\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 29s 575us/sample - loss: 0.1409 - accuracy: 0.9529\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.1341 - accuracy: 0.9543\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 29s 577us/sample - loss: 0.1338 - accuracy: 0.9551\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 29s 577us/sample - loss: 0.1278 - accuracy: 0.9575\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 29s 575us/sample - loss: 0.1280 - accuracy: 0.9564\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 29s 577us/sample - loss: 0.1220 - accuracy: 0.9594\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 29s 580us/sample - loss: 0.1221 - accuracy: 0.9593\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.1187 - accuracy: 0.9605\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 29s 577us/sample - loss: 0.1187 - accuracy: 0.9598\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 29s 577us/sample - loss: 0.1153 - accuracy: 0.9615\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 29s 576us/sample - loss: 0.1073 - accuracy: 0.9643\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.1138 - accuracy: 0.9617\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 29s 575us/sample - loss: 0.1071 - accuracy: 0.9639\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 29s 576us/sample - loss: 0.1046 - accuracy: 0.9649\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 29s 575us/sample - loss: 0.1023 - accuracy: 0.9657\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 29s 575us/sample - loss: 0.1007 - accuracy: 0.9664\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.0976 - accuracy: 0.9671\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.0970 - accuracy: 0.9672\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.0978 - accuracy: 0.9680\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.0941 - accuracy: 0.9687\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 29s 580us/sample - loss: 0.0896 - accuracy: 0.9702\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 29s 576us/sample - loss: 0.0886 - accuracy: 0.9700\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.0896 - accuracy: 0.9707\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 29s 575us/sample - loss: 0.0910 - accuracy: 0.9693\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 29s 577us/sample - loss: 0.0846 - accuracy: 0.9717\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 29s 576us/sample - loss: 0.0848 - accuracy: 0.9717\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.0827 - accuracy: 0.9724\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.0863 - accuracy: 0.9715\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 29s 581us/sample - loss: 0.0800 - accuracy: 0.9733\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 29s 576us/sample - loss: 0.0800 - accuracy: 0.9734\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 29s 578us/sample - loss: 0.0780 - accuracy: 0.9738\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 29s 572us/sample - loss: 0.0785 - accuracy: 0.9736\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 29s 574us/sample - loss: 0.0761 - accuracy: 0.9748\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 29s 572us/sample - loss: 0.0770 - accuracy: 0.9745\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 29s 573us/sample - loss: 0.0761 - accuracy: 0.9746\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 29s 572us/sample - loss: 0.0752 - accuracy: 0.9753\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 29s 573us/sample - loss: 0.0704 - accuracy: 0.9760\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 29s 571us/sample - loss: 0.0702 - accuracy: 0.9774\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 29s 576us/sample - loss: 0.0670 - accuracy: 0.9772\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 29s 571us/sample - loss: 0.0698 - accuracy: 0.9764\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 31s 627us/sample - loss: 0.0675 - accuracy: 0.9777\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 29s 581us/sample - loss: 0.0685 - accuracy: 0.9774\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 29s 582us/sample - loss: 0.0676 - accuracy: 0.9776\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 29s 584us/sample - loss: 0.0677 - accuracy: 0.9772\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 29s 583us/sample - loss: 0.0641 - accuracy: 0.9784\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 29s 583us/sample - loss: 0.0704 - accuracy: 0.9763\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 29s 580us/sample - loss: 0.0651 - accuracy: 0.9783\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 29s 582us/sample - loss: 0.0658 - accuracy: 0.9781\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 29s 581us/sample - loss: 0.0635 - accuracy: 0.9791\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 29s 587us/sample - loss: 0.0637 - accuracy: 0.9796\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 29s 581us/sample - loss: 0.0635 - accuracy: 0.9795\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 29s 584us/sample - loss: 0.0607 - accuracy: 0.9799\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 29s 583us/sample - loss: 0.0601 - accuracy: 0.9796\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 29s 584us/sample - loss: 0.0592 - accuracy: 0.9802\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 29s 580us/sample - loss: 0.0630 - accuracy: 0.9798\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 29s 583us/sample - loss: 0.0565 - accuracy: 0.9809\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 29s 579us/sample - loss: 0.0551 - accuracy: 0.9811\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 29s 583us/sample - loss: 0.0577 - accuracy: 0.9807\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 29s 580us/sample - loss: 0.0588 - accuracy: 0.9809\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 29s 584us/sample - loss: 0.0567 - accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 29s 582us/sample - loss: 0.0585 - accuracy: 0.9806\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 29s 585us/sample - loss: 0.0535 - accuracy: 0.9824\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 29s 581us/sample - loss: 0.0572 - accuracy: 0.9809\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 29s 583us/sample - loss: 0.0563 - accuracy: 0.9813\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 29s 580us/sample - loss: 0.0521 - accuracy: 0.9829\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 29s 583us/sample - loss: 0.0545 - accuracy: 0.9820\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 29s 582us/sample - loss: 0.0516 - accuracy: 0.9830\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 29s 581us/sample - loss: 0.0529 - accuracy: 0.9824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2a123cb940>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Day021_Transfer_Learning_HW.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
